{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fde312e",
   "metadata": {},
   "source": [
    "# Data Streams\n",
    "\n",
    "Data streams allow client applications to publish named streams of arbitrary structured data which are added to recordings and are available for live visualisation.\n",
    "\n",
    "Each entry in a single data stream is is required to have a unique, always ascending timestamp. The entry data itself can be a Python type such as an `dict`, `tuple`, `list`, `int`, `float`, or a numpy array. Data stream entries are useful for storing changes to data over time - for example you might store the (x, y) position of a ball as it moves within a pong simulation.\n",
    "\n",
    "Data streams also support named attributes. Updates to an attribute replace earlier values for that attribute and are best used for meta data such as the current and eventually final score of a gameplay simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4133cf18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top level RecordingView:\n",
      "\n",
      "RecordingView of file: /data/recordings/2024-12-19_15-20-34.893+10-00_recording.h5\n",
      "    file:         Direct access to the underlying PyTables object\n",
      "    attributes:   A view of the recording attributes\n",
      "    spikes:       Access spikes stored in the recording\n",
      "    stims:        Access stims stored in the recording\n",
      "    samples:      Access raw frames of samples stored in the recording\n",
      "    data_streams: A colletion of recorded data streams \n",
      "\n",
      "Data Streams in recording:\n",
      "\n",
      "Data Streams:\n",
      "    example_data_stream \n",
      "\n",
      "Example Data Stream attributes:\n",
      "\n",
      "/data_stream/example_data_stream._v_attrs (AttributeSet), 5 attributes:\n",
      "   [CLASS := 'GROUP',\n",
      "    TITLE := '',\n",
      "    VERSION := '1.0',\n",
      "    application := {'score': 2, 'another_attrbute': [0, 1, 2, 3], 'new_attribute': 9.9},\n",
      "    name := 'example_data_stream'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cl\n",
    "import numpy\n",
    "\n",
    "with cl.open() as neurons:\n",
    "    # Create a named data stream - by default, it will be added to any active or future recordings.\n",
    "    data_stream = \\\n",
    "        neurons.create_data_stream(\n",
    "            name='example_data_stream',\n",
    "            attributes={ 'score': 0, 'another_attrbute': [0, 1, 2, 3] })\n",
    "    \n",
    "    # Start a recording\n",
    "    recording = neurons.record(stop_after_seconds=1)\n",
    "    \n",
    "    timestamp = neurons.timestamp()\n",
    "    \n",
    "    # Add some data stream entries with unique, ascending timestamps:\n",
    "    data_stream.append(timestamp + 0, { 'arbitrary': 'data' })\n",
    "    data_stream.append(timestamp + 1, ['of', 'arbitrary', 'size'])\n",
    "    data_stream.append(timestamp + 2, 'and type.')\n",
    "    data_stream.append(timestamp + 3, numpy.array([2**64 - 1, 2**64 - 2, 2**64 - 3], dtype=numpy.uint64))\n",
    "    \n",
    "    # Update a single attribute\n",
    "    data_stream.set_attribute('score', 1)\n",
    "    \n",
    "    # Update multiple attributes at once\n",
    "    data_stream.update_attributes({ 'score': 2, 'new_attribute': 9.9 })\n",
    "    \n",
    "    recording.wait_until_stopped()\n",
    "    \n",
    "recording_view = recording.open()\n",
    "\n",
    "print(\"Top level RecordingView:\\n\")\n",
    "print(recording_view, '\\n')\n",
    "\n",
    "print(\"Data Streams in recording:\\n\")\n",
    "print(recording_view.data_streams, '\\n')\n",
    "\n",
    "print(\"Example Data Stream attributes:\\n\")\n",
    "print(recording_view.data_streams.example_data_stream.attributes, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b849a",
   "metadata": {},
   "source": [
    "## DataStreamView\n",
    "\n",
    "The HD5F format does not natively provide for an inituitive way to efficiently store an indexed list of items where any item can be a different size. For this reason, data stream data is stored end-to-end in a simple array of bytes, and another HDF5 dataset is used to associate timestamps with indexes into this data for retrieval.\n",
    "\n",
    "We provide a DataStreamView class which makes working with data streams comfortable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cae1c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 entries in example_data_stream.\n"
     ]
    }
   ],
   "source": [
    "data_stream = recording_view.data_streams.example_data_stream\n",
    "\n",
    "print(f\"There are {len(data_stream)} entries in example_data_stream.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bcf024",
   "metadata": {},
   "source": [
    "Entries in the data stream can be iterated over in a few ways.\n",
    "\n",
    "Iterating over all (timestamp, data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6199e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2664 {'arbitrary': 'data'}\n",
      "\n",
      " 2665 ['of', 'arbitrary', 'size']\n",
      "\n",
      " 2666 and type.\n",
      "\n",
      " 2667 [18446744073709551615 18446744073709551614 18446744073709551613]\n"
     ]
    }
   ],
   "source": [
    "for timestamp, data in data_stream.items():\n",
    "    print('\\n', timestamp, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e30ad8",
   "metadata": {},
   "source": [
    "Iterating over timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abdc49b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2664\n",
      "\n",
      " 2665\n",
      "\n",
      " 2666\n",
      "\n",
      " 2667\n"
     ]
    }
   ],
   "source": [
    "for timestamp in data_stream.keys():\n",
    "    print('\\n', timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8300f86",
   "metadata": {},
   "source": [
    "Iterating over data directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af9d685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'arbitrary': 'data'}\n",
      "\n",
      " ['of', 'arbitrary', 'size']\n",
      "\n",
      " and type.\n",
      "\n",
      " [18446744073709551615 18446744073709551614 18446744073709551613]\n"
     ]
    }
   ],
   "source": [
    "for data in data_stream.values():\n",
    "    print('\\n', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418101de",
   "metadata": {},
   "source": [
    "Data can also be retrieved by using a timestamp as an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64862ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2664 {'arbitrary': 'data'}\n",
      "\n",
      " 2665 ['of', 'arbitrary', 'size']\n",
      "\n",
      " 2666 and type.\n",
      "\n",
      " 2667 [18446744073709551615 18446744073709551614 18446744073709551613]\n"
     ]
    }
   ],
   "source": [
    "for timestamp in data_stream.keys():\n",
    "    data = data_stream[timestamp]\n",
    "    print('\\n', timestamp, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b66f63",
   "metadata": {},
   "source": [
    "You can also retrieve entries for a range of timestamps.\n",
    "\n",
    "**Note:** an entry must have a timestamp less than the end timestamp to be returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b96744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range ending at last timestamp:\n",
      "\n",
      " 2665 ['of', 'arbitrary', 'size']\n",
      "\n",
      " 2666 and type.\n",
      "\n",
      "\n",
      "Range ending at last timestamp plus one:\n",
      "\n",
      " 2665 ['of', 'arbitrary', 'size']\n",
      "\n",
      " 2666 and type.\n",
      "\n",
      " 2667 [18446744073709551615 18446744073709551614 18446744073709551613]\n"
     ]
    }
   ],
   "source": [
    "# TODO: SUPPORT DIRECT INDEX WITHIN KEYS TO AVOID THIS HACK\n",
    "timestamps       = [timestamp for timestamp in data_stream.keys()]\n",
    "second_timestamp = timestamps[1]\n",
    "last_timestamp   = timestamps[-1]\n",
    "\n",
    "print('Range ending at last timestamp:')\n",
    "\n",
    "for timestamp, data in data_stream.items_for_range(second_timestamp, last_timestamp):\n",
    "    print('\\n', timestamp, data)\n",
    "    \n",
    "print('\\n\\nRange ending at last timestamp plus one:')\n",
    "\n",
    "for timestamp, data in data_stream.items_for_range(second_timestamp, last_timestamp + 1):\n",
    "    print('\\n', timestamp, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9a4b0e",
   "metadata": {},
   "source": [
    "Similarly, you can retrieve just the timestamps or just the data within a range of timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5484796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2665\n",
      "\n",
      " 2666\n",
      "\n",
      " 2667\n"
     ]
    }
   ],
   "source": [
    "for timestamp in data_stream.keys_for_range(second_timestamp, last_timestamp + 1):\n",
    "    print('\\n', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f283840a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ['of', 'arbitrary', 'size']\n",
      "\n",
      " and type.\n",
      "\n",
      " [18446744073709551615 18446744073709551614 18446744073709551613]\n"
     ]
    }
   ],
   "source": [
    "for data in data_stream.values_for_range(second_timestamp, last_timestamp + 1):\n",
    "    print('\\n', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b006d",
   "metadata": {},
   "source": [
    "## Data Stream Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5518be",
   "metadata": {},
   "source": [
    "Just as the root group can have attributes, each data stream has its own attributes. Any custom attributes added to the data stream by the client application are added in the `application` dict attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "179e1472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data_stream/example_data_stream._v_attrs (AttributeSet), 5 attributes:\n",
      "   [CLASS := 'GROUP',\n",
      "    TITLE := '',\n",
      "    VERSION := '1.0',\n",
      "    application := {'score': 2, 'another_attrbute': [0, 1, 2, 3], 'new_attribute': 9.9},\n",
      "    name := 'example_data_stream']\n",
      "\n",
      "The name of the data stream is 'example_data_stream'.\n",
      "The value of the data stream attribute 'score' is '2'.\n"
     ]
    }
   ],
   "source": [
    "print(data_stream.attributes)\n",
    "print()\n",
    "print(f\"The name of the data stream is '{data_stream.attributes.name}'.\")\n",
    "print(f\"The value of the data stream attribute 'score' is '{data_stream.attributes.application['score']}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b33fc23",
   "metadata": {},
   "source": [
    "## Working Without DataStreamView\n",
    "\n",
    "If you prefer, you can work directly with data stream data within the HDF5 file. Each data stream has an `index` table dataset that contains rows with a `timestamp`, `start_index`, and `end_index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50bdd2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2664 0 16\n",
      "\n",
      " 2665 16 35\n",
      "\n",
      " 2666 35 45\n",
      "\n",
      " 2667 45 110\n"
     ]
    }
   ],
   "source": [
    "raw_data_stream = recording_view.file.root.data_stream.example_data_stream\n",
    "for row in raw_data_stream.index:\n",
    "    timestamp, start_index, end_index = row['timestamp'], row['start_index'], row['end_index']\n",
    "    print('\\n', timestamp, start_index, end_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b49081",
   "metadata": {},
   "source": [
    "For efficiency, `row[0]`, `row[1]`, and `row[2]` can be used instead of `row['timestamp']`, `row['start_index']`, `row['end_index']`.\n",
    "\n",
    "The `start_index` and `end_index` values specify which range of bytes from the `data` dataset are needed to access the data for `timestamp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0e3bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2664 [129 169  97 114  98 105 116 114  97 114 121 164 100  97 116  97]\n",
      "\n",
      " 2665 [147 162 111 102 169  97 114  98 105 116 114  97 114 121 164 115 105 122\n",
      " 101]\n",
      "\n",
      " 2666 [169  97 110 100  32 116 121 112 101  46]\n",
      "\n",
      " 2667 [133 196   2 110 100 195 196   4 116 121 112 101 163  60 117  56 196   4\n",
      " 107 105 110 100 196   0 196   5 115 104  97 112 101 145   3 196   4 100\n",
      "  97 116  97 196  24 255 255 255 255 255 255 255 255 254 255 255 255 255\n",
      " 255 255 255 253 255 255 255 255 255 255 255]\n"
     ]
    }
   ],
   "source": [
    "for row in raw_data_stream.index:\n",
    "    timestamp, start_index, end_index = row[0], row[1], row[2]\n",
    "    data_bytes = raw_data_stream.data[start_index:end_index]\n",
    "    print('\\n', timestamp, data_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551539b2",
   "metadata": {},
   "source": [
    "The data is stored in msgpack serialised form, so we need to use msgpack to deserialise the data. **Note:** If numpy arrays were directly stored in the data stream, you'll want to use use msgpack_numpy to assist the deserialisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a6232a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without msgpack_numpy:\n",
      "\n",
      " 2664 {'arbitrary': 'data'} \n",
      "  (<class 'dict'>\n",
      "\n",
      " 2665 ['of', 'arbitrary', 'size'] \n",
      "  (<class 'list'>\n",
      "\n",
      " 2666 and type. \n",
      "  (<class 'str'>\n",
      "\n",
      " 2667 {b'nd': True, b'type': '<u8', b'kind': b'', b'shape': [3], b'data': b'\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfd\\xff\\xff\\xff\\xff\\xff\\xff\\xff'} \n",
      "  (<class 'dict'>\n",
      "\n",
      "With msgpack_numpy:\n",
      "\n",
      " 2664 {'arbitrary': 'data'} \n",
      "  (<class 'dict'>\n",
      "\n",
      " 2665 ['of', 'arbitrary', 'size'] \n",
      "  (<class 'list'>\n",
      "\n",
      " 2666 and type. \n",
      "  (<class 'str'>\n",
      "\n",
      " 2667 [18446744073709551615 18446744073709551614 18446744073709551613] \n",
      "  (<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import msgpack\n",
    "import msgpack_numpy\n",
    "\n",
    "print(\"Without msgpack_numpy:\")\n",
    "\n",
    "for row in raw_data_stream.index:\n",
    "    timestamp, start_index, end_index = row[0], row[1], row[2]\n",
    "    data_bytes = raw_data_stream.data[start_index:end_index]\n",
    "    data = msgpack.unpackb(data_bytes)\n",
    "    print('\\n', timestamp, data, f\"\\n  ({type(data)}\")\n",
    "    \n",
    "print(\"\\nWith msgpack_numpy:\")\n",
    "\n",
    "for row in raw_data_stream.index:\n",
    "    timestamp, start_index, end_index = row[0], row[1], row[2]\n",
    "    data_bytes = raw_data_stream.data[start_index:end_index]\n",
    "    data = msgpack.unpackb(data_bytes, object_hook=msgpack_numpy.decode)\n",
    "    print('\\n', timestamp, data, f\"\\n  ({type(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c1ec4f",
   "metadata": {},
   "source": [
    "## Next\n",
    "\n",
    "[Real-Time Visualisation](CL-04.%20Real-Time%20Visualisation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
